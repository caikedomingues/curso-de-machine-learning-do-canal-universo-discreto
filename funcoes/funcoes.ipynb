{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cee9aa8b",
   "metadata": {},
   "source": [
    "Resolvi criar essa pasta que irá conter as principais funções que iremos\n",
    "utilizar durante as aualas, dessa maneira, não precisarei ficar reescrevendo\n",
    "os mesmos blocos de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1f9d43",
   "metadata": {},
   "source": [
    "Método que irá carregar os arquivos e acessar os valores das colunas. O objetivo da criação desse método é facilitar a leitura dos arquivos csv\n",
    "e facilitar a captura dos valores das colunas, algo que, aparentemente,\n",
    "iremos fazer com frequência nas aulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f5c6931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da função que irá carregar o dataset e capturar\n",
    "# os valores da coluna. A função irá conter 2 parametros:\n",
    "# O nome do aqruivo que está sendo acessado e o tipo de\n",
    "# delimitador (caractere que separa os valores).\n",
    "# Observação: O valor padrão do delimitador será None,\n",
    "# pois, caso o arquivo tenha como separador a \",\"(padrão\n",
    "# dos arquivos csv) não será necessário especificarmos um\n",
    "# delimitador\n",
    "def carregar_Dataset(nome_arquivo, delimitador = None):\n",
    "    \n",
    "    # Ira importar a biblioteca pandas que irá acessar o dataset\n",
    "    # e manipulará os dados.\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Variável que irá acessar o dataset através do seu nome e do\n",
    "    # seu delimitador\n",
    "    base_de_dados = pd.read_csv(nome_arquivo, delimiter=delimitador)\n",
    "    \n",
    "    # Variável que irá acessar os valores de todas as colunas exceto\n",
    "    # a ultima (geralmente a variável x representa um conjunto de carac\n",
    "    # teristicas que serão usadas para treinar modelos de predição/class\n",
    "    # ificação)\n",
    "    x = base_de_dados.iloc[:,:-1].values\n",
    "    \n",
    "    # Variável que irá conter os valores apenas da ultima coluna. Geralmente\n",
    "    # a variável y é o alvo da predição/classificação e contém os valores reais\n",
    "    # da base de dados que serão comparados com a previsão ou classificação do\n",
    "    # modelo\n",
    "    y = base_de_dados.iloc[:, -1].values\n",
    "    \n",
    "    # Ira retornar os valores de x e y\n",
    "    return x, y "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edc1f01",
   "metadata": {},
   "source": [
    "Função que irá preencher dados faltantes da base de dados usando a classe SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b3b6639",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Criação da função que terá como objetivo substituir valores Not a Number\n",
    "# ou seja linhas que não possuem valores. A função irá receber como parametro\n",
    "# 2 valores: a variável que terá os valores preenchidos e o tipo de estratégia\n",
    "# que o SimpleImputer irá utilizar para preencher esses dados como por exemplo\n",
    "# a média ou a mediana.\n",
    "def preencherDadosFaltantes(variavel_x, estrategia):\n",
    "    \n",
    "    # Import da classe SimpleImputer da biblioteca sklearn.impute.\n",
    "    # Essa será a classe que irá preencher os valores que estão faltando\n",
    "    # no dataset. Vale lembrar que a classe SimpleImputer só deve ser uti\n",
    "    # lizada em valores numéricos.\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    \n",
    "    # Import da biblioteca numpy que irá possibilitar que acessamos\n",
    "    # os valores nan do dataset através do construtor da classe Simple\n",
    "    # Imputer.\n",
    "    import numpy as np\n",
    "    \n",
    "    # Instância da classe (criação do objeto) SimpleImputer. O construtor\n",
    "    # da classe irá receber o missing_values que indica o tipo de valor\n",
    "    # faltante e a estratégia que será utilizada para preenche-los. \n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy=estrategia)\n",
    "    \n",
    "    # Irá aplicar os preenchimentos no dataset no intervalo selecionado.\n",
    "    # O intervalo irá pegar todas as colunas exceto a primeira (que geralm\n",
    "    # ente contém ids ou nomes).\n",
    "    variavel_x[:,1:] = imputer.fit_transform(variavel_x[:,1:])\n",
    "    \n",
    "    # Retorna da variável x com as alterações\n",
    "    return variavel_x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65f427b",
   "metadata": {},
   "source": [
    "Criação da função que irá transformar dados categóricos em rótulos numéricos\n",
    "com o objetivo de conseguir inclui-los nos modelos de predição/classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f664fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da função que irá rotular de forma numérica os dados categóricos\n",
    "# (dados do tipo texto). A função irá receber como paarametro a variável que\n",
    "# contém os valores categóricos\n",
    "def rotulacao(variavel_x):\n",
    "    \n",
    "    # Import da classe LabelEncoder da biblioteca sklearn.preprocessing\n",
    "    # que é usada para transformar rótulos categóricos (como nomes) em\n",
    "    # inteiros (0, 1, 2)\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    \n",
    "    # Import da biblioteca pandas que contém a função dummies\n",
    "    # que aplica o one-hot encoding nos dados (rotulação binária\n",
    "    # que evita que os modelos considerem os rótulos numéricos como\n",
    "    # valores matemáticos ou estatisticos)\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Import da biblioteca numpy que irá conter a função insert\n",
    "    # que irá inserir os rótulos numericos dos dados categóricos\n",
    "    import numpy as np\n",
    "    \n",
    "    # Instância da classe (criação do objeto) LabelEncoder\n",
    "    label_encoder_x = LabelEncoder()\n",
    "    \n",
    "    # Irá criar e aplicar a rotulação numérica nos valores da primeira\n",
    "    # coluna (os nomes dos alunos) \n",
    "    variavel_x[:, 0] = label_encoder_x.fit_transform(variavel_x[:, 0])\n",
    "    \n",
    "    \n",
    "    # Função que irá aplicar a rotulação binária nos dados categóricos\n",
    "    binario = pd.get_dummies(variavel_x[:,0])\n",
    "    \n",
    "    # Ira usar a função insert da biblioteca numpy para inserir os rótulos\n",
    "    # binários no conjunto de dados. A função irá receber como parametro:\n",
    "    # variavel_x: conjunto que irá receber os valores\n",
    "    # 0: A posição que os dados ficaram no conjunto\n",
    "    # binario.values: Os valores que serão inseridos\n",
    "    # axis = 1: A indicação que estamos inserindo uma nova coluna.\n",
    "    variavel_x = np.insert(variavel_x, 0, binario.values, axis=1)\n",
    "    \n",
    "    # Retorni da função com o resultado\n",
    "    return variavel_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ce382d",
   "metadata": {},
   "source": [
    "Criação da função que irá separar os dados em treino e teste com o objetivo de\n",
    "criar modelos de predição/classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c22ee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que irá separa o conjunto de dados em treino e teste.\n",
    "# A função irá receber como argumento:\n",
    "# x: Irá conter o conjunto de valores (caracteristicas ) que\n",
    "# serão utilizadas na classificação/predição do modelo.\n",
    "# y: Variável alvo da classificação ou predição do modelo\n",
    "def treino_teste(x, y, tamanho_teste):\n",
    "    \n",
    "    # Importa da função train_test_split da biblioteca sklearn.model\n",
    "    # selection que tem como objetivo separar os dados em treino e teste\n",
    "    # para construção de modelos.\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    # Variáveis que irão receber os valores da função train_test_split\n",
    "    # com a separação dos dados (em treino e teste).\n",
    "    # Xtrain: Ira receber a parte de treino dos dados (geralmente a maior\n",
    "    # parte deles)\n",
    "    # XTest: Irá conter as características (features) do conjunto de dados de teste.\n",
    "    # YTrain: Ira conter os valores reais que o modelo usará para aprender\n",
    "    # YTest: Ira conter os valores reais da predição/classificação\n",
    "    #que serão comparados com os resultados do modelo\n",
    "    XTrain, XTest, YTrain, YTest = train_test_split(x, y, test_size= tamanho_teste)\n",
    "    \n",
    "    return XTrain, XTest, YTrain, YTest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c207be99",
   "metadata": {},
   "source": [
    "Função que irá realizar a padronização dos valores do dataset com o objetivo\n",
    "de lidar com valores que estão discrepantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "598df33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que irá realizar a padronização dos dados com o objetivo\n",
    "# de definir uma escala de valores que busca evitar a descrepância\n",
    "# entre os valores. A função ira receber como argumentos os dados de\n",
    "# treino e teste.\n",
    "def padronizacao(treino, teste):\n",
    "    \n",
    "    # Import da classe StandardScaler da biblioteca skelarn.preprocessing\n",
    "    # que tem como objetivo aplicar uma escala com média 0  e desvio padrão 1 que irá padronizar o conjunto de valores da base de dados.\n",
    "    \n",
    "    # Observação: Vale lembra que a biblioteca preprocessing tem como\n",
    "    # função preparar os dados antes de utilizarmos como por exemplo\n",
    "    # na definição de rótulos, na padronização de valores, etc.\n",
    "    \n",
    "    # Desvio padrão: Medida que indica a distância que os valores estão\n",
    "    # da média, ou seja, quanto mais próximo da média (ou igual a média)\n",
    "    # mais baixo é o desvio padrão, já quanto mais distante, maior é o \n",
    "    # desvio padrão. A classificação de \"desvio padrão alto ou baixo\" não considera se o valor individual é maior ou menor que a média.\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    # Instância da classe (criação do objeto) Standard\n",
    "    scale_x = StandardScaler()\n",
    "    \n",
    "    # fit_transform da classe standardscaler que irá\n",
    "    # calcular e aplicar nos dados de treino a padronização\n",
    "    # dos dados\n",
    "    treino = scale_x.fit_transform(treino)\n",
    "    \n",
    "    # transform da classe StandardScaler que irá aplicar \n",
    "    # nos dados de teste a padronização criada nos dados \n",
    "    # de treino\n",
    "    teste = scale_x.transform(teste)\n",
    "    \n",
    "    # Retorno das variáveis com os resultados\n",
    "    return treino, teste"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
